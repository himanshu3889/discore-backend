name: discore

services:
  # PostgreSQL 
  postgres:
    image: postgres:15-alpine
    container_name: discore-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # - ./migrations:/docker-entrypoint-initdb.d:ro  # for migrations
    ports: ["5432:5432"]
    networks: [discore-net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  mongodb:
    image: bitnami/mongodb:latest
    container_name: discore-mongodb
    environment:
      - MONGODB_ROOT_PASSWORD=${MONGODB_ROOT_PASSWORD}
      - MONGODB_DATABASE=${MONGODB_DATABASE}
      - MONGODB_USERNAME=${MONGODB_USERNAME}
      - MONGODB_PASSWORD=${MONGODB_PASSWORD}
    volumes:
      - mongodb_data:/bitnami/mongodb  # Bitnami uses /bitnami, not /data/db
    ports: ["27017:27017"]
    networks: [discore-net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  # Redis with modules
  redis:
    image: redis/redis-stack:latest
    container_name: discore-redis
    environment:
      REDIS_ARGS: >
        --requirepass ${REDIS_PASSWORD}
        --save 900 1
        --save 300 10
        --save 60 10000
        --appendonly yes
        --appendfsync no     
    volumes: [redis_data:/data]
    ports: ["6379:6379"]
    networks: [discore-net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 20s

  # Elasticsearch 
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.2.3
    container_name: discore-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
    ulimits: {memlock: {soft: -1, hard: -1}}
    volumes: [elasticsearch_data:/usr/share/elasticsearch/data]
    ports: ["9200:9200"]
    networks: [discore-net]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s


  kafka:
    image: apache/kafka:latest
    container_name: discore-kafka
    ports:
      - "9092:9092"   # External clients connect here
      - "9093:9093"   # Internal controller communication (KRaft)
    environment:
      # Explicitly enable KRaft mode (Kafka without ZooKeeper)
      KAFKA_KRAFT_MODE: 'true'
      
      # Core KRaft settings - no ZooKeeper needed
      # Unique ID for this broker node 
      KAFKA_NODE_ID: 1
      # This node acts as both broker (handles data) and controller (manages cluster state)
      KAFKA_PROCESS_ROLES: "broker,controller"
      # Defines the quorum voters for controller election (format: id@host:port)
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@discore-kafka:9093"
      
      # Cluster identity - generate once with: kafka-storage.sh random-uuid
      # This UUID persists cluster metadata across restarts
      CLUSTER_ID: "Mk3OEYBSD34fcwNTJENDM2Qk"
      
      # Listener configuration
      # PLAINTEXT: Client traffic (9092), CONTROLLER: Internal KRaft quorum (9093)
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      # What clients see when connecting (uses KAFKA_HOST env var or defaults to localhost)
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${KAFKA_HOST:-localhost}:9092
      # Maps listener names to security protocols (PLAINTEXT = no auth)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      # Which listener brokers use to talk to each other
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      # Which listener is reserved for the KRaft controller quorum
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      
      # Storage paths - where Kafka stores topic data and KRaft metadata
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      
      # Topic settings
      # Prevent accidental topic creation 
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      # Replication factor for internal offset topic
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Replication factor for transaction state logs
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # Minimum in-sync replicas for transactions
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      
      # Retention and cleanup - tuned for local development 
      # Keep logs for 24 hours 
      KAFKA_LOG_RETENTION_HOURS: 24
      # Max retention size: 1GB per partition
      KAFKA_LOG_RETENTION_BYTES: 1073741824
      # Log segment size: 100MB (smaller segments = faster cleanup after bursts)
      KAFKA_LOG_SEGMENT_BYTES: 104857600
      
      # Performance tuning 
      # Threads handling network requests (3 handles burst traffic fine)
      KAFKA_NUM_NETWORK_THREADS: 3
      # Threads handling disk I/O (4 is sweet spot for burst writes without CPU hog)
      KAFKA_NUM_IO_THREADS: 4
      # TCP send buffer size (100KB - helps with burst responses)
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      # TCP receive buffer size (100KB - handles large produce batches efficiently)
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      # Max request size (100MB - allows clients to send large batches for burst loading)
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      
      # Group coordinator settings
      # No startup delay for consumer groups 
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # Require all replicas to acknowledge offset commits (strong consistency)
      KAFKA_OFFSETS_COMMIT_REQUIRED_ACKS: -1
      
      # JVM heap size (1GB is plenty for handling 100k bursts locally)
      KAFKA_HEAP_OPTS: "-Xmx1G -Xms1G"

    volumes:
      # Persist Kafka data across container restarts
      - kafka_data:/var/lib/kafka/data
    networks: [discore-net]
    restart: unless-stopped
    healthcheck:
      # Check if Kafka is responsive by listing topics
      test: ["CMD", "kafka-topics.sh", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 5


  # Main App
  app:
    build:
      context: ./                      # Points to project root
      dockerfile: ./Dockerfile  # Path from context to Dockerfile
    container_name: discore-app
    ports:
      - "${APP_PORT}:8080"
      - "8081:8081"  # Health probe
    environment:
      - POSTGRES_HOST
      - POSTGRES_PORT
      - POSTGRES_DB
      - POSTGRES_USER
      - POSTGRES_PASSWORD
      - REDIS_HOST
      - REDIS_PORT
      - REDIS_PASSWORD
      - KAFKA_HOST
      - KAFKA_PORT
      - ELASTICSEARCH_HOST
      - ELASTICSEARCH_PORT
      - RATE_LIMIT_PER_MINUTE
      - MONGODB_HOST 
      - MONGODB_USERNAME
      - MONGODB_PASSWORD
      - MONGODB_DATABASE
    env_file: ./.env
    depends_on:
      postgres: {condition: service_healthy}
      mongodb: {condition: service_healthy}
      redis: {condition: service_healthy}
      # elasticsearch: {condition: service_healthy}
      # kafka: {condition: service_healthy}
    networks: [discore-net]
    restart: unless-stopped
    security_opt: [no-new-privileges:true]
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8081/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  # Monitoring (200MB)
  prometheus:
    image: prom/prometheus:latest
    container_name: discore-prometheus
    extra_hosts:
      - "host.docker.internal:host-gateway"  # for the localhost listen
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus  
    ports: ["${PROMETHEUS_PORT}:9090"]
    networks: [discore-net]
    profiles: [monitoring]
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: discore-grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
    volumes: [grafana_data:/var/lib/grafana]
    ports: ["${GRAFANA_PORT}:3000"]
    networks: [discore-net]
    profiles: [monitoring]
    restart: unless-stopped

  loki:
    image: grafana/loki:latest
    container_name: discore-loki
    ports: ["3100:3100"]
    volumes:
      - ./monitoring/loki.yml:/etc/loki/loki.yml 
      - loki_data:/loki
    networks: [discore-net]
    profiles: [monitoring]

  # Exporters
  redis-exporter:
    image: oliver006/redis_exporter:latest
    environment:
      REDIS_ADDR: "redis://redis:6379"
    ports:
      - "9121:9121"
    depends_on:
      - redis

  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    environment:
      DATA_SOURCE_URI: "postgres:5432/testdb?sslmode=disable"
      DATA_SOURCE_USER: "postgres"
      DATA_SOURCE_PASS: "postgres"
    ports:
      - "9187:9187"
    depends_on:
      - postgres

  mongodb-exporter:
    image: percona/mongodb_exporter:0.40
    command: --mongodb.uri=mongodb://admin:admin@mongo:27017 --collect-all
    ports:
      - "9216:9216"
    depends_on:
      - mongodb

  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    command: ["--kafka.server=kafka:9092"]
    ports:
      - "9308:9308"
    depends_on:
      - kafka

  elasticsearch-exporter:
    image: prometheuscommunity/elasticsearch-exporter:latest
    command: --es.uri=http://elasticsearch:9200 --es.all --es.indices --es.shards
    ports:
      - "9114:9114"
    depends_on:
      - elasticsearch

volumes:
  postgres_data:
  mongodb_data: 
  redis_data:
  elasticsearch_data:
  kafka_data:
  prometheus_data:
  grafana_data:
  loki_data:
  

networks:
  discore-net:
    driver: bridge